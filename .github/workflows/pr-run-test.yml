name: pr_run_test

on:
  pull_request:
    branches:
      - "main"
    paths-ignore:
      - "docs/**"
      - "**.md"
  workflow_dispatch:
  schedule:
    - cron:  '56 01 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  BASE_SCORE: '{"MMBench_V11_MINI":{"Qwen2.5-VL-7B-Instruct":0.8727272727272727,"InternVL3-8B":0.90909091,"llava-onevision-qwen2-0.5b-ov-hf":0.43636364},"MMStar_MINI":{"Qwen2.5-VL-7B-Instruct":0.6266666666666667,"InternVL3-8B":0.6933333333333334,"llava-onevision-qwen2-0.5b-ov-hf":0.36},"AI2D_MINI":{"Qwen2.5-VL-7B-Instruct":0.7975708502024291,"InternVL3-8B":0.8137651821862348,"llava-onevision-qwen2-0.5b-ov-hf":0.8178137651821862},"OCRBench_MINI":{"Qwen2.5-VL-7B-Instruct":16.6,"InternVL3-8B":17.1,"llava-onevision-qwen2-0.5b-ov-hf":5.8}}'
  HF_HUB_CACHE: /mnt/shared-storage-user/large-model-center-share-weights/hf_hub
  HF_HUB_OFFLINE: 1
  CONDA_PATH: /mnt/shared-storage-user/opencompass-shared/qa-llm-cicd/miniconda3
  WORK_PATH: /mnt/shared-storage-user/mllm/qa-llm-cicd/pr_wkdir/VLMEvalKit/VLMEvalKit
  CONDA_ENV: vlm_pr_test
  KUBEBRAIN_CLUSTER_ENTRY: https://h.pjlab.org.cn
  KUBEBRAIN_NAMESPACE: ailab-opencompass

jobs:
  prepare_env:
    if: ${{!cancelled()}}
    runs-on: [yidian_cu12_mllm]
    steps:
      - name: clone_repo
        uses: actions/checkout@v3
      - name: reinstall vlmeval
        run: |
          . ${{env.CONDA_PATH}}/bin/activate
          conda activate ${{env.CONDA_ENV}}
          pip uninstall vlmeval -y
          pip install . -i https://pkg.pjlab.org.cn/repository/pypi-proxy/simple/ --trusted-host pkg.pjlab.org.cn --no-cache-dir
          pip install numpy==1.23.0 transformers==4.57.1 transformers_stream_generator -i https://pkg.pjlab.org.cn/repository/pypi-proxy/simple/ --trusted-host pkg.pjlab.org.cn --no-cache-dir
          pip install flash-attn --no-build-isolation -i https://pkg.pjlab.org.cn/repository/pypi-proxy/simple/ --trusted-host pkg.pjlab.org.cn --no-cache-dir
